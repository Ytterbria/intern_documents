*LLM 
LLM是agent的大脑,对于输入的指令进行语言理解,
然后进行推理和规划,决定下一步做什么.
接着进行自然语言输出 -> 给用户或工具返回结果Í

*Tools
LLM的能力有限,它不会自己上网,查数据库,看天气,找资料等. 所以给它配备外部的工具. 工具本质上就是一些 函数/API/外部服务
.调用流程: LLM识别需要工具 -> 生成调用参数 -> 系统执行工具 -> 返回结果
-> LLM 基于结果继续进行推理/ 回复给用户
.常见的工具例如: 
信息获取: 搜索引擎,数据库,向量检索
算力增强: Python REPL ,计算引擎, 
外部系统交互: 邮件,日历,天气,系统等
任务执行工具: 代码执行,文件读写,API 调用

实际开发中的重点,其实就是要注意定义工具的Schema(输入输出格式),控制工具的权限边界,还要提供相应的错误处理(如果工具挂了,agent能fallback)

*Memory 
LLM是大脑, 那么memory就是长期的智慧
.短期记忆
存放最近的上下文,通常是prompt buffer,可以把最近的几轮对话拼起来喂给LLM
但是上下文太长会导致token爆炸,需要做合理的截断/压缩处理

.长期记忆
存储知识或历史数据, 实现方式有: 
向量数据库: 把文本转Embedding,存储在Milvus,Pinecone,等
检索增强RAG: 先检索相关的知识,再拼接进Prompt
知识图谱: 可以更加结构化地存储实体关系

.过程记忆: 记录过去进行的哪些决策,使用了哪些工具,方便智能体改变未来行为

.语义记忆: 更抽象的总结记忆,把细节概括成规律,例如可以总结某个用户的长期偏好,然后形成profile

*策略
策略决定了智能体如何选择行动,这是agent和传统普通的chatbot的最大区别
.ReAct(Reason + Act)
LLM先生成推理过程,再执行调用工具,然后再用工具结果继续进行思考 -> 最终回答
适合通用型的agent

.Planning
先让LLM产出一份任务计划(多步执行),再逐步执行并更新计划,常常用在复杂的工作流/任务拆分场景. 这也是我在学习中喜欢的模式,先让AI给知识框架,再深入某一个小节的具体各种细枝末节进行学习

.Reflection
Agent 在执行后会进行复盘,优化下次的行为,有些类似人类的学习能力

.Multi-Agent Strategys
任务拆给不同角色的Agent,需要有很好的协调策略(投票,仲裁,角色分工)
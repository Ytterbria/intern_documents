新技术的产生往往是因为不够方便. 懒是生产技术发展的最高动力

从数据出发,一步一步进行优化,大数据的存储,计算,处理等.逐渐理清大数据的框架

1. Hadoop是什么
由于大数据的5V特征,导致读写存储等处理压力巨大,需要专门设计相应框架进行处理. 
数据太大放不下,难处理,可以将一份大文件切分成数据块block(128M), 同时在多个dataNode备份保证可靠性. Hadoop因此屏蔽了大数据的处理细节,对外提供读写API便可
2. 多服务器的文件读写? --HDFS 
对于从多台服务器(Node)里读写数据,又显得太麻烦. 需要一个软件来屏蔽多服务器的读写复杂性.
因此出现了HDFS(Hadoop Distributed File System), Hadoop的分布式文件系统
3.如何计算 ? --mapReduce
不可能将HDFS里的文件全部数据都加载到内存中处理,这样服务器扛不住. 但是可以参考数据存储的思路,可以将数据切分成很多分片(split),分给多个服务器进行计算,最后再将结果聚合起来
map负责定义每个分片数据里的每行订单如何计算
reduce负责定义如何把map函数算好的结果汇总起来计算最终结果
4.计算任务的调度和资源分配 ? --Yarn
MapReduce的计算任务数量也不少,每个任务都需要CPU,内存等服务器计算资源,因此还需要一个中间层,负责调度资源分配. 它将每个计算任务所需要的资源抽象为容器(container,实际上是一个被限制了CPU和内存等计算资源的jvm进程)
5.不想写一堆map和reduce函数? -- Hive
为了让数据分析人员不用写大量的mapReduce函数,能够用sql一样方便的查询大数据.出现了Hive
(虽然我觉得sql也没多好写,人类的懒是永无止境的,就像是又有嫌sql麻烦做出mybatis框架的)
它可以将用户输入的类似SQL的语句,解析为一个个mapreduce任务,可以理解为sql和mapreduce的一个中间层. 
6.数据分析读写磁盘太慢了? -- Spark
mapreduce 会吧计算过程中产生的中间结果放在磁盘中,导致频繁的磁盘读写,效率很低. 
为了提升性能,可以把中间结果放在内存中,极大提升处理速度. 而hive本身不是为spark设计的,还需要hive on spark适配层,所以又设计了spark sql,可以跟spark更好的搭配
7.数据的是实行处理? -- flink
之前的mapreduce或spark都是为离线数据处理设计的(一批批处理,攒够了才处理下一批. 攒的过程浪费时间),为了更高的实时性,又设计了flink. 实现了在线数据处理的场景
8.毫秒级别的在线实时读写? -- Hbase
hive从海量数据中读写一两条数据是分钟级别的操作,flink虽然实时性高,但是一般面向数据处理,热不是在线读写. Hbase分布式数据库,实现了在海量数据中的高并发读写数据的场景
9.
